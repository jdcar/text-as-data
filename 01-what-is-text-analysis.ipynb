{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e097b0",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"200\" src=\"Picture1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e90c3-90b0-4535-b8d6-0c53f5746ce6",
   "metadata": {},
   "source": [
    "# 1. Text as Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170ee75-4725-4b63-bbcf-68b03e4b2697",
   "metadata": {},
   "source": [
    "### Jamie Carlstone, Authority Metadata Librarian, Metadata Services\n",
    "<li><a href=\"jamie.carlstone@northwestern.edu\">jamie.carlstone@northwestern.edu</a></li>\n",
    "<li>847.491.3487</li>\n",
    "<li><a href=\"https://orcid.org/0000-0002-9288-328X\">https://orcid.org/0000-0002-9288-328X</a></li>\n",
    "<p>bio: I joined Northwestern Libraries in Fall 2019. Prior to Northwestern, I worked at the University of Chicago and the University of Illinois. In April 2021, I earned a coding bootcamp certificate from the NU School of Professional Studies. This presentation uses Python, but I am more familiar with Javascript.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b73cd-95a5-4f1b-b48e-cd0331e020a5",
   "metadata": {},
   "source": [
    "## About this session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f6d5c-7629-4076-afca-6b62d2a075ec",
   "metadata": {},
   "source": [
    "<p><strong>Text as Data</strong> is a part of the 2022 annual Northwestern RRF. Instead of slides, I am going to present using Jupyter Notebook. Jupyter allows for running code in distinct cells alongside documentation, which is very useful for teaching anything with code.</p>\n",
    "<p>The training I took on text analysis was provided by the <a href=\"http://labs.jstor.org/tapi-courses/\">Ithaka TAP institute</a> this last summer. You can find text analysis trainings (and more!) on the <a href=\"https://constellate.org/tutorials\">Constellate website.</a> The GitHub repositories for the classes I took are available at: <a href=\"https://github.com/melaniewalsh/Working-with-Twitter-Data-TAPI-2022\">Working with Twitter Data</a>, <a href=\"https://github.com/wjbmattingly/intro-nlp-tap-2022\">Introduction to NLP with spaCy</a>, and <a href=\"https://github.com/wjbmattingly/tap-2022-pandas/blob/main/day-01.ipynb\">Introduction to Pandas</a>.\n",
    "<p>The programming language used in this notebook today is Python. Python is popular with humanities and social sciences researchers and librarians. <strong>R</strong> is another popular language for text analysis.</p>\n",
    "<p>For instructions on how to use Jupyter notebooks: <a href=\"https://docs.jupyter.org/en/latest/start/index.html\">https://docs.jupyter.org/en/latest/start/index.html</a></p>\n",
    "<p>This is meant to be a high level overview of text analysis. Try not to worry too much about any coding in the presentation, which is for demonstration purposes.</p>\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f118279-9585-4114-ad13-650008cdfeaf",
   "metadata": {},
   "source": [
    "### Goals\n",
    "You will know more about:\n",
    "<ol>\n",
    " <li>What is text analysis</li>\n",
    " <li>Strategies for getting datasets</li>\n",
    " <li>Preparing data for analysis</li>\n",
    "  <li>Analyzing text</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea356ca6-0434-470c-98a5-35c29c3b2cd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What is Text Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b010c-631c-41fc-8dcc-8afc0ea67936",
   "metadata": {},
   "source": [
    "Text analysis (also called Text mining) is the use of large datasets of text to do pattern analysis. While the analysis of patterns in text is not new, more recent technologies make the processing of large datasets easier. This session will show some ways to do text analysis with and without coding knowledge. I hope by the end of the session, you will know where to start if you are interested in learning how to do textual analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448a2e3-13be-427d-aeb7-8d01fb69b10a",
   "metadata": {},
   "source": [
    "## How do scholars use text analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213188e9-7deb-4d31-8dc3-00c0ad9ef375",
   "metadata": {},
   "source": [
    "Text analysis can be used to:    \n",
    "<ul>\n",
    " <li>Show trends</li>\n",
    " <li>Create visualizations</li>\n",
    "    <li>Tell stories about data</li>\n",
    " <li>Discover new things about texts</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9474afa-533d-4f66-a136-de7b78bd0bc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### \"Rescued History\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f3bb8-b5ae-4a02-a8f9-5c755ab56589",
   "metadata": {},
   "source": [
    "<a href=\"https://beta.nsf.gov/news/rescued-history\">https://beta.nsf.gov/news/rescued-history</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0be183e-6fc5-4962-bf6a-c94feeb7f198",
   "metadata": {},
   "source": [
    "*Mendenhall's team realized that to search tens or even hundreds of thousands of books, articles and letters, they'd need considerably more computing power than available on a typical university computer cluster. They consulted with colleagues on campus who were members of the National Science Foundation (NSF)-supported Extreme Science and Engineering Discovery Environment\n",
    "(XSEDE), the most advanced collection of integrated advanced digital resources and services in the world. Those colleagues helped them identify the Blacklight supercomputer at the Pittsburgh Supercomputing Center\n",
    "Blacklight (now retired) allowed the researchers to analyze 20,000 documents from the HathiTrust\n",
    "and JSTOR databases that were known to contain information about black women and to create a computational model based on this corpus of document. They are now using this model to study the entire 800,000 documents in both databases.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b16a0e-e21e-4cfe-8b52-0783af616951",
   "metadata": {},
   "source": [
    "### \"America's Public Bible\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e6689-5e28-4ec6-8c90-b950fed880ca",
   "metadata": {},
   "source": [
    "<a href=\"https://americaspublicbible.org/\">https://americaspublicbible.org/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec26cf-6081-42ab-8ac2-9027e8bb53ab",
   "metadata": {},
   "source": [
    "This website visualizes the frequency of Bible quotes in historical American newspapers. The dataset used is Chronicling America: Historic American Newspapers from the Library of Congress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d51de-f9ec-4904-abf6-6b9313eef1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://americaspublicbible.org/\" width=\"1500\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab97f2c-d144-49e0-9ed9-9c2404d9e023",
   "metadata": {},
   "source": [
    "## More information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bec6d",
   "metadata": {},
   "source": [
    "<p><a href=\"https://voyant-tools.org/\">https://voyant-tools.org/</a></p>\n",
    "    <p><a href=\"https://tapor.ca/home\">https://tapor.ca/home</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
