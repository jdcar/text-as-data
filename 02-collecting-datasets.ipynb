{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4beabf1",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"200\" src=\"Picture1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab5c76-befc-4945-820e-ef6ad7774547",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Collecting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a4a41-f142-4683-8146-628e53d83ad8",
   "metadata": {},
   "source": [
    "There are several ways to create a dataset. Today we are going to talk about the following:\n",
    "<ol>\n",
    "  <li>Downloading existing datasets</li>\n",
    "  <li>Application Programming Interfaces (APIs)</li>\n",
    "  <li>Web scraping</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3d41c-3ff6-4e6c-a693-8036305c0ec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Responsible text collection and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdbffba-2b46-48df-8834-473edc82d5b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Before collecting data from the web, it is important to follow documentation, rights, and use guidelines to be sure the extraction and use of data is legal. You will also want to think about the ethics of your proposed textual analysis project. \n",
    "\n",
    "A useful list of questions can be found on page 21 of <a href=\"https://psyarxiv.com/xvrhm/\">Reflexivity in Quantitative Research: A Rationale and Beginner’s Guide,</a> (Jamieson, M. K., Govaart, G. H., & Pownall, M.) including:\n",
    "<ul><li>Why do I want to research this group?</li><li>If I am using existing datasets, are there any silent assumptions in this dataset?\"</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220b4b6-cc2e-4ed2-815f-8ab01c8ff16f",
   "metadata": {},
   "source": [
    "What can you do to ensure responsible textual analysis practices?\n",
    "<ul>\n",
    "  <li>Ask a librarian: The library has a lot of expertise on how to ethically use data. The library has a Copyright Librarian, Digital Humanities Librarian, and a Data Management Librarian. You can also reach out to your subject specialists. Librarians can help guide you and even reach out to our vendors if you want to do text analysis on library subscriptions.</li>\n",
    "  <li>Look for the <a href=\"https://creativecommons.org/\">Creative Commons</a> logo or other licenses. These will explain the permissions for using data on the webpage. The absence of a license does not mean there are no restrictions or ethical considerations.</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c8bc0-0a1d-4117-9e66-7a48ef44bc65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download existing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e9398b-cc36-4da9-9d46-3b466e05dd5d",
   "metadata": {},
   "source": [
    "There are plenty of existing datasets already available to download. This is the easiest way to get data because there is no coding needed. However, it limits the data you can work with--someone else needs to prepare the dataset and make it available to download. It is often already structured, which can be good or bad depending on what is your goal. This can limit your research. However, it is easier to work with existing datasets, and it is a good place to start with text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8bb8ae-809c-408f-b26a-c9b0cad262df",
   "metadata": {},
   "source": [
    "These are a few examples of free large datasets available online to download:\n",
    "\n",
    "| Type of Data | Name | Link | Description |\n",
    "| --- | --- | --- | --- |\n",
    "| Book | HathiTrust | https://www.hathitrust.org/hathifiles | Metadata for all of HathiTrust books |\n",
    "| Emails | Enron Email dataset | https://www.cs.cmu.edu/~./enron/ | .5 million emails from senior managers at Enron (FEC provided) |\n",
    "| Reviews | Yelp reviews | https://www.yelp.com/dataset | Access to >6 million Yelp reviews |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61833570-4599-4400-a1f1-f1ab1977179e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91f6f6-4e43-44f8-89d3-71880267b200",
   "metadata": {},
   "source": [
    "APIs (Application Programming Interface) are an excellent way to access data on the web. Of course, there are limitations: it does require the owner of the data to make it available and provide permissions. The person retrieving the data needs coding skills to make data requests. API data is typically structured as json or xml data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3978f59-276e-4f71-86f9-eea8f0bcb315",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa7e0d-b8b0-43e6-bd55-3e562859a20e",
   "metadata": {},
   "source": [
    "Twitter has a powerful API that is available to almost anyone with a Twitter account. Python tools, like twarc, make accessing this data relatively simple with a little Python knowledge. Let's try getting data with the Twitter API!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77324891-db51-4c23-858d-7cd573279d63",
   "metadata": {},
   "source": [
    "twarc is a command line tool that allows us to easily query for tweets. Lucky for us you can use Jupyter notebooks to run command lines by add the \"!\" in front of the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e3e75-8173-4d09-9ac2-bab14fb6c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You should only need to do this command once on your computer. If it's already installed you'll see a message that says \"Requirement already satisfied\"\n",
    "#! pip install --upgrade twarc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91773106-33c4-4332-b308-542c29688c52",
   "metadata": {},
   "source": [
    "APIs usually require keys (unique codes) that are tied to users. This is because APIs always have limitations--restricting users, the number of queries, limits to what data can be accessed, etc. A lot of API data is behind a paywall. My Twitter API key is in another file called Constants for security reasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37680c9d-5246-41fc-8fab-ed398e372c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This tells the file to look for an API key in another file called Constants:\n",
    "import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016deaa-25cd-4b64-a49a-7c5a7d6c7b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This gets that API key and renames it \"t\"\n",
    "t = Constants.BEARER_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636cdcc1-17ae-4616-8a40-80015255e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This configures twarc so the Twitter API knows you're ok to acccess the data\n",
    "#!printf t | twarc2 configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c2e33-7d1a-440c-8d89-54320a679dcf",
   "metadata": {},
   "source": [
    "Finally it is time to have some fun with the API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06452cfd-54c3-4897-9262-36cc7bb6a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limits to 50, results for tweets containing a term/phrase in the last week\n",
    "!twarc2 search --limit 50 \"pizza\" results3.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d157b56d-48ac-4862-a3d4-89a5c382581c",
   "metadata": {},
   "source": [
    "The results file doesn't look pretty right now because it is structured as json data. For now, we're going to leave it there but there is much more that can be done with the twarc Twitter API tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ee4df-66b7-493f-8c0d-a31282e7c84a",
   "metadata": {},
   "source": [
    "As a Northwestern user, you can apply for <a href=\"https://developer.twitter.com/en/products/twitter-api/academic-research\">academic access to the Twitter API</a>. This provides access to all public tweets by just adding `--archive` to the request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe777a-cb3e-47f0-a26e-9e1862dc5e2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3310e-1c1d-4062-9eff-9ef0262eb823",
   "metadata": {},
   "source": [
    "Web scraping, or web harvesting, uses code to pull data from webpages. This is the data collection strategy that likely requires the most programming knowledge--it is also carries the most risk. If you are going to scrape a lot of data from a website, the best approach is to seek permission first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66b45cd-07ce-4bca-b3a9-d31a2c666b32",
   "metadata": {},
   "source": [
    "There are web scraper tools available like this <a href=\"https://chrome.google.com/webstore/detail/web-scraper-free-web-scra/jnhgnonknehpejjnehehllkliplmbmhn?hl=en\">browser extension</a> that will scrape a single page. You can even scrape a single webpage using Google sheets! But as a researcher you will likely want to scrape a lot of data at a time, which requires more programming knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac6451-e7f0-4841-8d4b-8a7bfad8efcf",
   "metadata": {},
   "source": [
    "Webpages can be extracted using <a href=\"https://support.google.com/docs/answer/3093339?hl=en\">formulas</a> in Google sheets. We can test scraping a wikipedia page by using this formula:`=ImportHTML(\"https://en.wikipedia.org/wiki/Academy_Award_for_Best_Supporting_Actress\", \"table\", 6)` in a Google sheet: <a href=\"https://docs.google.com/spreadsheets/d/1vITQtcemjB_AYO3134Vi_TOiIR_AaHItSwXBE3_vOOg/edit\">https://docs.google.com/spreadsheets/d/1vITQtcemjB_AYO3134Vi_TOiIR_AaHItSwXBE3_vOOg/edit</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42acac1e-2a14-4d12-af70-2362e0768b27",
   "metadata": {},
   "source": [
    "A librarian can help with collecting data with web scraping. If you want to scrape data provided through library subscriptions we can help you with getting persmissions from our vendors. This way you can scrape web data without risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62318df-1a00-4f11-9fd3-95eb82d78911",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## More information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7af72",
   "metadata": {},
   "source": [
    "Responsible text analysis:\n",
    "\n",
    "Jamieson, Michelle K., Gisela H. Govaart, and Madeleine Pownall. 2022. “Reflexivity in Quantitative Research: A Rationale and Beginner’s Guide.” PsyArXiv. February 23. <a href=\"doi:10.31234/osf.io/xvrhm.\">doi:10.31234/osf.io/xvrhm</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82844fea",
   "metadata": {},
   "source": [
    "Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55adb5a",
   "metadata": {},
   "source": [
    "APIs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c448b",
   "metadata": {},
   "source": [
    "Web scraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff71fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
