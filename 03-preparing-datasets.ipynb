{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9566fb",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"200\" src=\"Picture1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38942b",
   "metadata": {},
   "source": [
    "# 3. Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45243ddf-55b0-4e6d-b829-cbb89b42226d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using NLP on texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e8662-49f1-4d84-a139-98e5ef91fb7d",
   "metadata": {},
   "source": [
    "Like any data analysis project, the data might to be prepared and cleaned before doing Natural Language Processing (NLP). This might include:\n",
    "<ul><li>Removing certain words</li>\n",
    "<li>Combining or removing chunks of text</li>\n",
    "<li>Converting words to lower case</li>\n",
    "<li>Removing punctuation or stop words</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c806a-42c2-439c-ac10-ecf24cce005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the line below if spaCy is not downloaded already.\n",
    "#! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea6d2b-103a-49ce-bc9a-740e6edbd8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475ada0-089a-417e-8831-cc80a56f7936",
   "metadata": {},
   "source": [
    "SpaCy has stopwords, which are words that you might want to remove before doing NLP. The code in the next cell will print the stop words so you can see the list. More advanced NLP projects might create their own stopwords, depending on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97a577-8e19-4591-861b-d33467a2971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "print(len(stopwords))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68dc61a-496a-47b8-823d-98035abbc74f",
   "metadata": {},
   "source": [
    "I've added a file `little-women.txt` which contains the first chapter of Little Women. I am only including 1 chapter because the whole book was too much text for spaCy to process at once. Running the code below loads that text and renames it `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dc168-2f40-49ad-b5b9-77c757e6d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Little Women text file\n",
    "with open (\"little-women.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe913665-097b-43ab-9c34-c39daa4f2c5a",
   "metadata": {},
   "source": [
    "Next, we will print out the first 500 words so we can see how the text looks unprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ce8d8-e463-4cb5-8d57-1137a904061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a49d9",
   "metadata": {},
   "source": [
    "Sometimes it is easier to work with text if all the words are lowercase. We can lowercase the text easily with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8988ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()\n",
    "print (text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd953c7-99aa-473c-94b9-9f20407f7a87",
   "metadata": {},
   "source": [
    "Still looks pretty normal right? Now, we're going to use spaCy, which will allow us to take that text and turn it into tokens. When the text becomes tokens, we can use NLP to do textual analysis. After we print the doc as tokens it will look the same, but the computer will understand the text as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3716d7b-de2e-46ed-8efa-bce6fe01149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "print (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ebe7c-1682-4485-bec9-2a56756b56a8",
   "metadata": {},
   "source": [
    "By running the next code, we see the text is 21,861 characters but when it is processed into tokens, the length becomes 5,473. As tokens, it is possible to do NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2f202-735d-4e93-8e1a-491f53ea6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(text))\n",
    "print (len(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8dc85",
   "metadata": {},
   "source": [
    "This is the code to run to remove stop words and punctuation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.is_stop == False: #if the token is not a stop word, keep it\n",
    "        if token.pos_ != \"PUNCT\": #if the token is not punctuation, keep it\n",
    "            print (token.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e486955-94fc-4231-9302-f3c7f7f86777",
   "metadata": {},
   "source": [
    "The code in the next cell prints the token and linguistic features associated with that word or punctuation. When we can label the text as their parts of speech we can do analysis on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b6479-979a-4b3a-91c5-8ac422d27e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc[100:125]:\n",
    "    if token.is_stop == False:\n",
    "        if token.pos_ != \"PUNCT\":\n",
    "            print (token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "                token.shape_, token.is_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09eaa93",
   "metadata": {},
   "source": [
    "What is this telling us? The tags are identifying the parts of speech of the tokens, excluding stop words and punctuation. More information on linguistic features can be found at: https://spacy.io/usage/linguistic-features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1a956-f9c2-4cf0-a840-e4697c32336e",
   "metadata": {},
   "source": [
    "<p>Take this line: `faces face NOUN NNS nsubj xxxx True False`\n",
    "<p>Faces: the token\n",
    "<p>Face: Lemma, or the base form of the word (how it might be in the dictionary)\n",
    "<p>NOUN: Part of speech\n",
    "<p>NNS: detailed part-of-speech tag.\n",
    "<p>nsubj: Syntactic dependency (the relation between tokens)\n",
    "<p>xxxx: Word shape, like capitalization, punctuation, digits\n",
    "<p>True: It is alphabetical\n",
    "<p>False: Is not on the stop word list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b146822-1b11-40cf-acae-35825699e5b1",
   "metadata": {},
   "source": [
    "At this point we've already done a lot: turned text into tokens, removed stop words and punctuation, and annotated text to show information about the parts of speech. The next notebook we are going to do a little more textual analysis, including visualizations, tables, and comparisons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469bd34",
   "metadata": {},
   "source": [
    "## More information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c767b",
   "metadata": {},
   "source": [
    "<p><a href=\"https://nlp.stanford.edu/\">Stanford NLP</a></p>\n",
    "<p><a href=\"https://spacy.io/\">spaCy</a></p>\n",
    "<p><a href=\"https://openrefine.org/\">OpenRefine</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8b2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
